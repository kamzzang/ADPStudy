{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 정규 표현식\n",
    "* 출처 : 서적 \"잡아라! 텍스트 마이닝 with 파이썬\"\n",
    "* 문자열이 주어진 규칙에 일치하는 지, 일치하지 않는지 판단할 수 있다.    \n",
    "  정규 표현식을 이용하여 특정 패턴을 지니니 문자열을 찾을 수 있어 텍스트 데이터 사전 처리 및    \n",
    "  크롤링에서 주로 쓰임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = '기상청은 슈퍼컴퓨터도 서울지역의 집중호우를 제대로 예측하지 못했다고 설명했습니다. 왜 오류가 발생했\\\n",
    "습니다. 왜 오류가 발생했는지 자세히 분석해 예측 프로그램을 보완해야 할 대목입니다. 관측 분야는 개선될 여지가\\\n",
    "있습니다. 지금 보시는 왼쪽 사진이 현재 천리안 위성이 촬영한 것이고 오른쪽이 올해 말 쏘아 올릴 천리안 2A호가 \\\n",
    "촬영한 영상입니다. 오른쪽이 왼쪽보다 태풍의 눈이 좀 더 뚜렷하고 주변 구름도 더 잘 보이죠. 새 위성을 통해 태풍\\\n",
    " 구름 등의 움직임을 상세히 분석하면 좀 더 정확한 예측을 할 수 있지 않을까 기대해 봅니다. 정구희 기자(koohee@sbs.co.kr)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(\"\\([A-Za-z0-9\\._+]+@[A-Za-z]+\\.(com|org|edu|net|co.kr)\\)\", \"\", string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \\([A-Za-z0-9\\._+]+ : 이메일 주소가 괄호로 시작하여 \\(특수문자를 원래 의미대로 쓰게 함)와 (로 시작    \n",
    "                     대괄호[ ] 안에 이메일 주소의 패턴을 입력(입력한 것 중 아무거나)    \n",
    "                     A-Z = 알파벳 대문자, a-z = 알파벳 소문자, 0-9 = 숫자, ._+ = .나 _나 +     \n",
    "                     마지막 +는 바로 앞에 있는 것이 최소 한번 이상 나와야 한다는 의미    \n",
    "* @ : 이메일 주소 다음에 @    \n",
    "* [A-Za-z]+ : 도메인 주소에 해당하는 알파벳 대문자나 소문자    \n",
    "* \\. : 도메인 주소 다음의 .    \n",
    "* (com|org|edu|net|co.kr)\\) : |는 or조건, 도메인 주소 마침표 다음의 패턴 마지막 )까지 찾음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이썬 정규표현식 기호 설명\n",
    "* '*' : 바로 앞 문자, 표현식이 0번 이상 반복\n",
    "* '+' : 바로 앞 문자, 표현식이 1번 이상 반복\n",
    "* '[]' : 대괄호 안의 문자 중 하나\n",
    "* '()' : 괄호안의 정규식을 그룹으로 만듬\n",
    "* '.' : 어떤 형태든 문자 1자\n",
    "* '^' : 바로 뒤 문자, 표현식이 문자열 맨 앞에 나타남\n",
    "* '$' : 바로 앞 문자, 표현식이 문자열 맨 뒤에 나타남\n",
    "* '{m}' : 바로 앞 문자, 표현식이 m회 반복\n",
    "* '{m,n}' : 바로 앞 문자, 표현식이 m번 이상, n번 이하 나타남\n",
    "* '|' : |로 분리된 문자, 문자열, 표현식 중 하나가 나타남(or조건)\n",
    "* '[^]' : 대괄호 안에 있는 문자를 제외한 문자가 나타남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a문자가 1번 이상 나오고 b 문자가 0번 이상 나오는 문자열 찾기\n",
    "r = re.compile(\"a+b*\")\n",
    "r.findall(\"aaaa, cc, bbbb, aabbb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대괄호를 이용해 대문자로 구성된 문자열 찾기\n",
    "r = re.compile(\"[A-Z]+\")\n",
    "r.findall(\"HOME, home\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^와 .을 이용하여 맨 앞에 a가 오고 그 다음에 어떠한 형태든 2개의 문자가 오는 문자열 찾기\n",
    "r = re.compile(\"^a..\")\n",
    "r.findall(\"abc, cba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중괄호 표현식 {m,n}을 이요하여 해당 문자열이 m번 이상 n번 이하 나타나는 패턴 찾기\n",
    "r = re.compile(\"a{2,3}b{2,3}\")\n",
    "r.findall(\"aabb, aaabb, ab, aab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile 메서드에 정규 표현식 패턴 지정, search로 정규 표현식 패턴과 일치하는 문자열의 위치 찾기\n",
    "# group을 통해 패턴과 일치하는 문자들을 그룹핑하여 추출\n",
    "p = re.compile(\".+:\")\n",
    "m = p.search(\"http://google.com\")\n",
    "m.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub : 정규 표현식과 일치하는 부분을 다른 문자로 치환\n",
    "p = re.compile(\"(내|나의|내꺼)\")\n",
    "p.sub(\"그의\", \"나의 물건에 손대지 마시오.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 대소문자 통일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n",
      "HELLO WORLD\n"
     ]
    }
   ],
   "source": [
    "s = 'Hello World'\n",
    "print(s.lower())\n",
    "print(s.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 숫자, 문장부호, 특수문자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'서울 부동산 가격이 올해 들어 평균 % 상승했습니다.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 숫자 제거\n",
    "p = re.compile(\"[0-9]+\")\n",
    "p.sub(\"\", '서울 부동산 가격이 올해 들어 평균 30% 상승했습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 서울 부동산 가격이 올해 들어 평균 30 상승했습니다 '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장부호, 특수문자 제거\n",
    "p = re.compile(\"\\W+\")\n",
    "p.sub(\" \", \"★서울 부동산 가격이 올해 들어 평균 30% 상승했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'주제_1 건강한 물과 건강한 정신 '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = p.sub(\" \", \"주제_1: 건강한 물과 건강한 정신!\")\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'주제 1 건강한 물과 건강한 정신 '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = re.compile(\"_\")\n",
    "p.sub(\" \", s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_Korean = ['추석','연휴','민족','대이동','시작','늘어','교통량','교통사고','특히','자동차','고장',\n",
    "                '상당수','차지','나타','것','기자']\n",
    "stopwords = ['가다','늘어','나타','것','기자']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['추석', '연휴', '민족', '대이동', '시작', '교통량', '교통사고', '특히', '자동차', '고장', '상당수', '차지']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in words_Korean if i not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "# 그냥하면 LookupError 발생하므로 다운로드가 필요함\n",
    "# import nltk\n",
    "# nltk.download() or nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chief',\n",
       " 'justice',\n",
       " 'roberts',\n",
       " ',',\n",
       " 'president',\n",
       " 'carter',\n",
       " ',',\n",
       " 'president',\n",
       " 'clinton',\n",
       " ',',\n",
       " 'president',\n",
       " 'bush',\n",
       " ',',\n",
       " 'president',\n",
       " 'obama',\n",
       " ',',\n",
       " 'fellow',\n",
       " 'americans',\n",
       " 'people',\n",
       " 'world',\n",
       " ',',\n",
       " 'thank',\n",
       " '.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_English = ['chief','justice','roberts',',','president','carter',',','president','clinton',',',\n",
    "                'president','bush',',','president','obama',',','fellow','americans','and','people',\n",
    "                'of','the','world',',','thank','you','.']\n",
    "[w for w in words_English if not w in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 같은 어근 동일화(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is import to be immers while you are python with python.al python have pothon poorli at least onc . "
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps_stemmer = PorterStemmer()\n",
    "\n",
    "new_text = 'It is important to be immersed while you are pythoning with python.\\\n",
    "All pythoners have pothoned poorly at least once.'\n",
    "\n",
    "words = word_tokenize(new_text)\n",
    "\n",
    "for w in words:\n",
    "    print(ps_stemmer.stem(w), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is import to be immers whil you ar python with python.all python hav pothon poor at least ont . "
     ]
    }
   ],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "LS_stemmer = LancasterStemmer()\n",
    "\n",
    "for w in words:\n",
    "    print(LS_stemmer.stem(w), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is important to be immersed while you are ing with .All ers have pothoned poorly at least once . "
     ]
    }
   ],
   "source": [
    "from nltk.stem.regexp import RegexpStemmer # 특정한 표현식을 일괄적으로 제거\n",
    "\n",
    "RS_stemmer = RegexpStemmer('python')\n",
    "\n",
    "for w in words:\n",
    "    print(RS_stemmer.stem(w), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram\n",
    "* n번 연이어 등장하는 단어들의 연쇄\n",
    "* 두 번 : 바이그램, 세 번 : 트라이그램(트라이그램 이상은 보편적으로 활용하지 않음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Chief', 'Justice') ('Justice', 'Roberts,') ('Roberts,', 'Preskdent') ('Preskdent', 'Carter,') ('Carter,', 'President') ('President', 'Clinton,') ('Clinton,', 'President') ('President', 'Bush,') ('Bush,', 'President') ('President', 'Obama,') ('Obama,', 'fellow') ('fellow', 'Americans') ('Americans', 'and') ('and', 'people') ('people', 'of') ('of', 'the') ('the', 'world,') ('world,', 'thank') ('thank', 'you.') ('you.', 'We,') ('We,', 'the') ('the', 'citizens') ('citizens', 'of') ('of', 'America') ('America', 'are') ('are', 'now') ('now', 'joined') ('joined', 'in') ('in', 'a') ('a', 'great') ('great', 'national') ('national', 'effort') ('effort', 'to') ('to', 'rebuild') ('rebuild', 'our') ('our', 'country') ('country', 'and') ('and', 'restore') ('restore', 'its') ('its', 'promise') ('promise', 'for') ('for', 'all') ('all', 'of') ('of', 'our') ('our', 'people.') ('people.', 'Together,') ('Together,', 'we') ('we', 'will') ('will', 'determine') ('determine', 'the') ('the', 'course') ('course', 'of') ('of', 'America') ('America', 'and') ('and', 'the') ('the', 'world') ('world', 'for') ('for', 'many,') ('many,', 'many') ('many', 'years') ('years', 'to') ('to', 'come.') ('come.', 'We') ('We', 'will') ('will', 'face') ('face', 'challenges.') ('challenges.', 'We') ('We', 'will') ('will', 'confront') ('confront', 'hardships,') ('hardships,', 'but') ('but', 'we') ('we', 'will') ('will', 'get') ('get', 'the') ('the', 'job') ('job', 'done.') "
     ]
    }
   ],
   "source": [
    "sentence = 'Chief Justice Roberts, Preskdent Carter, President Clinton, President Bush, President Obama, \\\n",
    "fellow Americans and people of the world, thank you. We, the citizens of America are now joined in a great \\\n",
    "national effort to rebuild our country and restore its promise for all of our people. Together, we will \\\n",
    "determine the course of America and the world for many, many years to come. We will face challenges. We \\\n",
    "will confront hardships, but we will get the job done.'\n",
    "\n",
    "grams = ngrams(sentence.split(), 2)\n",
    "\n",
    "for gram in grams:\n",
    "    print(gram, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 품사 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['친척들', '이', '모이', 'ㄴ', '이번', '추석', '차례상', '에서는', '단연', \"'\", '집값', \"'\", '이', '화제', '에', '오르', '아다', '.']\n",
      "['친척들', '이번', '추석', '차례상', '집값', '화제']\n",
      "[('친척들', 'N'), ('이', 'J'), ('모이', 'P'), ('ㄴ', 'E'), ('이번', 'N'), ('추석', 'N'), ('차례상', 'N'), ('에서는', 'J'), ('단연', 'M'), (\"'\", 'S'), ('집값', 'N'), (\"'\", 'S'), ('이', 'J'), ('화제', 'N'), ('에', 'J'), ('오르', 'P'), ('아다', 'E'), ('.', 'S')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Hannanum\n",
    "\n",
    "hannanum = Hannanum()\n",
    "\n",
    "print(hannanum.morphs(\"친척들이 모인 이번 추석 차례상에서는 단연 '집값'이 화제에 올랐다.\"))\n",
    "print(hannanum.nouns(\"친척들이 모인 이번 추석 차례상에서는 단연 '집값'이 화제에 올랐다.\"))\n",
    "print(hannanum.pos(\"친척들이 모인 이번 추석 차례상에서는 단연 '집값'이 화제에 올랐다.\", ntags=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['친척', '들', '이', '모이', 'ㄴ', '이번', '추석', '차례', '상', '에서', '는', '단연', \"'\", '집', '값', \"'\", '이', '화제', '에', '오르', '았', '다', '.']\n",
      "['친척', '이번', '추석', '차례', '차례상', '상', '집', '집값', '값', '화제']\n",
      "[('친척', 'NNG'), ('들', 'XSN'), ('이', 'JKS'), ('모이', 'VV'), ('ㄴ', 'ETD'), ('이번', 'NNG'), ('추석', 'NNG'), ('차례', 'NNG'), ('상', 'NNG'), ('에서', 'JKM'), ('는', 'JX'), ('단연', 'MAG'), (\"'\", 'SS'), ('집', 'NNG'), ('값', 'NNG'), (\"'\", 'SS'), ('이', 'MDT'), ('화제', 'NNG'), ('에', 'JKM'), ('오르', 'VV'), ('았', 'EPT'), ('다', 'EFN'), ('.', 'SF')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()\n",
    "\n",
    "print(kkma.morphs(\"친척들이 모인 이번 추석 차례상에서는 단연 '집값'이 화제에 올랐다.\"))\n",
    "print(kkma.nouns(\"친척들이 모인 이번 추석 차례상에서는 단연 '집값'이 화제에 올랐다.\"))\n",
    "print(kkma.pos(\"친척들이 모인 이번 추석 차례상에서는 단연 '집값'이 화제에 올랐다.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['친척', '들', '이', '모인', '이번', '추석', '차례상', '에서는', '단연', \"'\", '집값', \"'\", '이', '화제', '에', '올랐다', '.']\n",
      "['친척', '이번', '추석', '차례상', '단연', '집값', '이', '화제']\n",
      "[('친척', 'Noun'), ('들', 'Suffix'), ('이', 'Josa'), ('모인', 'Verb'), ('이번', 'Noun'), ('추석', 'Noun'), ('차례상', 'Noun'), ('에서는', 'Josa'), ('단연', 'Noun'), (\"'\", 'Punctuation'), ('집값', 'Noun'), (\"'\", 'Punctuation'), ('이', 'Noun'), ('화제', 'Noun'), ('에', 'Josa'), ('올랐다', 'Verb'), ('.', 'Punctuation')]\n",
      "['친척들', '이번', '이번 추석', '이번 추석 차례상', '단연', '집값', '이 화제', '추석', '차례상', '화제']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Twitter\n",
    "twitter = Twitter()\n",
    "\n",
    "print(twitter.morphs(\"친척들이 모인 이번 추석 차례상에서는 단연 '집값'이 화제에 올랐다.\"))\n",
    "print(twitter.nouns(\"친척들이 모인 이번 추석 차례상에서는 단연 '집값'이 화제에 올랐다.\"))\n",
    "print(twitter.pos(\"친척들이 모인 이번 추석 차례상에서는 단연 '집값'이 화제에 올랐다.\"))\n",
    "print(twitter.phrases(\"친척들이 모인 이번 추석 차례상에서는 단연 '집값'이 화제에 올랐다.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('little', 'JJ'), ('yellow', 'JJ'), ('dog', 'NN'), ('barked', 'VBD'), ('at', 'IN'), ('the', 'DT'), ('Persian', 'NNP'), ('cat.', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "tokens = \"The little yellow dog barked at the Persian cat.\".split()\n",
    "tags_en = pos_tag(tokens)\n",
    "\n",
    "print(tags_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
